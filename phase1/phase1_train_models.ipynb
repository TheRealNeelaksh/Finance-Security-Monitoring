{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5838bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhis\\anaconda3\\envs\\abhishek_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading and processing data...\n",
      "   Calculating distances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:04<00:00, 4163.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Training Isolation Forest...\n",
      "3. Training Autoencoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.63s/epoch, loss=0.00628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step\n",
      "   Autoencoder Threshold: 0.01902\n",
      "\n",
      "4. Validating System...\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "--- IMPOSSIBLE TRAVEL ATTACKS ---\n",
      "Total Injected: 524\n",
      "Caught by iForest: 340\n",
      "Caught by Autoencoder: 244\n",
      "\n",
      "--- DEVICE SPOOFING ATTACKS ---\n",
      "Total Injected: 725\n",
      "Caught by iForest: 373\n",
      "Caught by Autoencoder: 438\n",
      "\n",
      "✅ Phase 1 Complete. Models saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from geopy.distance import geodesic\n",
    "import joblib\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "# Initialize tqdm for Pandas\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "path=os.path.abspath('user_logins.csv')\n",
    "# ==========================================\n",
    "# PART 1: FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "print(\"1. Loading and processing data...\")\n",
    "df = pd.read_csv(path) \n",
    "\n",
    "# Convert timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values(by=['user_id', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "# A. Time Diff\n",
    "df['prev_time'] = df.groupby('user_id')['timestamp'].shift(1)\n",
    "df['time_diff_hours'] = (df['timestamp'] - df['prev_time']).dt.total_seconds() / 3600\n",
    "df['time_diff_hours'] = df['time_diff_hours'].fillna(0)\n",
    "\n",
    "# B. Distance & Velocity\n",
    "print(\"   Calculating distances...\")\n",
    "df['prev_lat'] = df.groupby('user_id')['lat'].shift(1)\n",
    "df['prev_lon'] = df.groupby('user_id')['lon'].shift(1)\n",
    "\n",
    "def get_geo_dist(row):\n",
    "    if pd.isna(row['prev_lat']): return 0.0\n",
    "    try:\n",
    "        return geodesic((row['prev_lat'], row['prev_lon']), (row['lat'], row['lon'])).km\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "df['dist_km'] = df.progress_apply(get_geo_dist, axis=1)\n",
    "df['velocity_kmh'] = df['dist_km'] / (df['time_diff_hours'] + 0.1)\n",
    "\n",
    "# C. Device Frequency\n",
    "device_counts = df.groupby(['user_id', 'device']).size().reset_index(name='count')\n",
    "total_counts = df.groupby('user_id').size().reset_index(name='total')\n",
    "device_stats = pd.merge(device_counts, total_counts, on='user_id')\n",
    "device_stats['device_trust_score'] = device_stats['count'] / device_stats['total']\n",
    "\n",
    "df = pd.merge(df, device_stats[['user_id', 'device', 'device_trust_score']], \n",
    "              on=['user_id', 'device'], how='left')\n",
    "\n",
    "df['hour_of_day'] = df['timestamp'].dt.hour\n",
    "\n",
    "# ==========================================\n",
    "# PART 2: MODEL TRAINING\n",
    "# ==========================================\n",
    "features = ['velocity_kmh', 'time_diff_hours', 'device_trust_score', 'hour_of_day']\n",
    "X = df[features]\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test = train_test_split(X_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- ISOLATION FOREST ---\n",
    "print(\"\\n2. Training Isolation Forest...\")\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "iso_forest.fit(X_train)\n",
    "joblib.dump(iso_forest, 'model_isolation_forest.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# --- AUTOENCODER ---\n",
    "print(\"3. Training Autoencoder...\")\n",
    "input_dim = X_train.shape[1]\n",
    "autoencoder = Sequential([\n",
    "    Input(shape=(input_dim,)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(2, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(input_dim, activation='sigmoid')\n",
    "])\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(X_train, X_train, epochs=10, batch_size=32, verbose=0, callbacks=[TqdmCallback(verbose=0)])\n",
    "autoencoder.save('model_autoencoder.h5')\n",
    "\n",
    "# Calc Threshold\n",
    "reconstructions = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - reconstructions, 2), axis=1)\n",
    "threshold = np.percentile(mse, 95)\n",
    "print(f\"   Autoencoder Threshold: {threshold:.5f}\")\n",
    "\n",
    "# ==========================================\n",
    "# PART 3: VALIDATION (FIXED LABELS)\n",
    "# ==========================================\n",
    "print(\"\\n4. Validating System...\")\n",
    "\n",
    "df['iso_pred'] = iso_forest.predict(X_scaled) \n",
    "df['ae_loss'] = np.mean(np.power(X_scaled - autoencoder.predict(X_scaled), 2), axis=1)\n",
    "\n",
    "# --- FIX: Updated strings to match your new data generator ---\n",
    "travel_attacks = df[df['attack_type'] == 'Impossible Travel']\n",
    "caught_iso = travel_attacks[travel_attacks['iso_pred'] == -1]\n",
    "caught_ae = travel_attacks[travel_attacks['ae_loss'] > threshold]\n",
    "\n",
    "print(f\"--- IMPOSSIBLE TRAVEL ATTACKS ---\")\n",
    "print(f\"Total Injected: {len(travel_attacks)}\")\n",
    "print(f\"Caught by iForest: {len(caught_iso)}\")\n",
    "print(f\"Caught by Autoencoder: {len(caught_ae)}\")\n",
    "\n",
    "# --- FIX: Updated strings to match your new data generator ---\n",
    "device_attacks = df[df['attack_type'] == 'Device Spoofing']\n",
    "caught_iso_dev = device_attacks[device_attacks['iso_pred'] == -1]\n",
    "caught_ae_dev = device_attacks[device_attacks['ae_loss'] > threshold]\n",
    "\n",
    "print(f\"\\n--- DEVICE SPOOFING ATTACKS ---\")\n",
    "print(f\"Total Injected: {len(device_attacks)}\")\n",
    "print(f\"Caught by iForest: {len(caught_iso_dev)}\")\n",
    "print(f\"Caught by Autoencoder: {len(caught_ae_dev)}\")\n",
    "\n",
    "print(\"\\n✅ Phase 1 Complete. Models saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d57a4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abhishek_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
